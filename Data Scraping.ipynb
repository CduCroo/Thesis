{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eff7cf3b-b797-4ab1-a5b5-ccab23b7bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c54dbc-6177-4042-9b6e-2eb7685ae380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_files_to_csv(xls_file, csv_file, output_folder):\n",
    "    # check if the file is HTML by reading the first few bytes\n",
    "    df = pd.read_html(xls_file)\n",
    "    for i, table in enumerate(df):\n",
    "        table.to_csv(os.path.join(output_folder, f\"{csv_file}.csv\"), index=False)\n",
    "    return\n",
    "\n",
    "def convert_all_files_in_folder(folder_path, output_folder):\n",
    "    # ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.xls') or file_name.endswith('.xlsx'):\n",
    "            xls_file = os.path.join(folder_path, file_name)\n",
    "            csv_file = file_name.split('.')[0]\n",
    "            convert_files_to_csv(xls_file, csv_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c38b494-0027-46f8-ae58-dba3838a3a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert season stats to csv\n",
    "folder_path = 'season stats'\n",
    "output_folder = 'season stats csv'\n",
    "convert_all_files_in_folder(folder_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3897d6c3-5203-46cc-9bca-5f918b0e9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file of games from season\n",
    "def get_csv_games(url, year):\n",
    "    # get tables from webpage\n",
    "    tables = pd.read_html(url)\n",
    "    \n",
    "    # first table has regular season data\n",
    "    games = tables[0]\n",
    "    \n",
    "    # rename columns\n",
    "    games = games.rename(columns = {\n",
    "        'G': 'G_Visitor',\n",
    "        'G.1': 'G_Home',\n",
    "        'Unnamed: 6': 'OT_SO',\n",
    "        'Att.': 'Attendance'\n",
    "    })\n",
    "    \n",
    "    # convert date entries to datetime\n",
    "    games['Date'] = pd.to_datetime(games['Date'])\n",
    "    \n",
    "    # add weekday column\n",
    "    games['Day'] = games['Date'].dt.day_name()\n",
    "    \n",
    "    # convert time entries to datetime\n",
    "    games['Time'] = pd.to_datetime(games['Time'], format = '%I:%M %p').dt.time\n",
    "\n",
    "    # create folder 'season results' if it doesn't exist\n",
    "    folder_path = 'season results'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    # save the dataframe as a csv file\n",
    "    season_str = f\"{year - 1}-{str(year)[2:]}\"\n",
    "    file_name = f\"{season_str} season results.csv\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    games.to_csv(file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1365831c-b472-4d2c-8e24-7f4aa65472e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://www.hockey-reference.com/leagues/NHL_{year}_games.html'\n",
    "\n",
    "for year in range(2014, 2025):\n",
    "    url = url_base.format(year = year)\n",
    "    get_csv_games(url, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d545bc9a-bff1-4435-9508-8e2d64c15ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arena capacities\n",
    "# url wikipedia: list of national hockey league arenas\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_National_Hockey_League_arenas#Defunct_teams\"\n",
    "\n",
    "# read tables\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "#### CURRENT ARENAS\n",
    "# keep only relevant table entries\n",
    "current_arenas_df = tables[0]\n",
    "current_arenas_df = current_arenas_df.drop(columns = ['Team', 'Image', 'Location', 'Ref(s)', 'Opened', 'Season of first NHL game'])\n",
    "\n",
    "# index by team\n",
    "current_arenas_df = current_arenas_df.set_index('Arena')\n",
    "\n",
    "# additional cleanup\n",
    "current_arenas_df.loc['Delta Center', 'Capacity'] = 16200\n",
    "current_arenas_df['Capacity'] = current_arenas_df['Capacity'].astype(int)\n",
    "\n",
    "all_arenas_df = current_arenas_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f46bc6-f873-45a8-814d-84a6f77078ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately, some arenas go by multiple names\n",
    "# imma just add these in myself lol\n",
    "\n",
    "# Crypto.com Arena - Staples Center\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Crypto.com Arena', 'Capacity']]}, index = ['Staples Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# BB&T Center - Amerant Bank Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Amerant Bank Arena', 'Capacity']]}, index = ['BB&T Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# BankAtlantic Center - Amerant Bank Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Amerant Bank Arena', 'Capacity']]}, index = ['BankAtlantic Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Pepsi Center - Ball Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Ball Arena', 'Capacity']]}, index = ['Pepsi Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Bell MTS Place - Canada Life Centre\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Canada Life Centre', 'Capacity']]}, index = ['Bell MTS Place'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# MTS Centre - Canada Life Centre\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Canada Life Centre', 'Capacity']]}, index = ['MTS Centre'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# PNC Arena - Lenovo Center\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Lenovo Center', 'Capacity']]}, index = ['PNC Arena'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Air Canada Centre - Scotiabank Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Scotiabank Arena', 'Capacity']]}, index = ['Air Canada Centre'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Scottrade Center - Enterprise Center\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Enterprise Center', 'Capacity']]}, index = ['Scottrade Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# SAP Center at San Hose - SAP Center\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['SAP Center', 'Capacity']]}, index = ['SAP Center at San Jose'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# HP Pavillion at San Hose - SAP Center\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['SAP Center', 'Capacity']]}, index = ['HP Pavillion at San Jose'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Verizon Center - Capital One Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Capital One Arena', 'Capacity']]}, index = ['Verizon Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# First Niagara Center - KeyBank Center\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['KeyBank Center', 'Capacity']]}, index = ['First Niagara Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Consol Energy Center - PPG Paints Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['PPG Paints Arena', 'Capacity']]}, index = ['Consol Energy Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Tampa Bay Times Forum - Amalie Arena\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Amalie Arena', 'Capacity']]}, index = ['Tampa Bay Times Forum'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Scotiabank Place - Canadian Tire Centre\n",
    "new_row = pd.DataFrame({'Capacity': [all_arenas_df.loc['Canadian Tire Centre', 'Capacity']]}, index = ['Scotiabank Place'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347dbcfb-d897-4f79-aa7c-ed70842184e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also add in old arenas\n",
    "\n",
    "# Arizona Coyotes - Gila River Arena/Jobing.com Arena\n",
    "# https://en.wikipedia.org/wiki/Desert_Diamond_Arena\n",
    "new_row = pd.DataFrame({'Capacity': 17125}, index = ['Jobing.com Arena'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "new_row = pd.DataFrame({'Capacity': 17125}, index = ['Gila River Arena'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# New York Islanders - Barclays Center\n",
    "# https://en.wikipedia.org/wiki/Barclays_Center\n",
    "new_row = pd.DataFrame({'Capacity': 15795}, index = ['Barclays Center'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# New York Islanders - Nassau Veterans Memorial Coliseum\n",
    "new_row = pd.DataFrame({'Capacity': 13900}, index = ['Nassau Veterans Memorial Coliseum'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Detroit Red Wings - Joe Louis Arena\n",
    "# https://en.wikipedia.org/wiki/Joe_Louis_Arena\n",
    "new_row = pd.DataFrame({'Capacity': 20027}, index = ['Joe Louis Arena'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])\n",
    "\n",
    "# Edmonton Oilers - Rexall Place\n",
    "# https://en.wikipedia.org/wiki/Northlands_Coliseum\n",
    "new_row = pd.DataFrame({'Capacity': 17100}, index = ['Rexall Place'])\n",
    "all_arenas_df = pd.concat([all_arenas_df, new_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c296878-57be-4f6f-9435-81260b4c582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file of arenas used per season\n",
    "def get_arenas(url_arenas, all_arenas_df):\n",
    "    # get tables from webpage\n",
    "    tables = pd.read_html(url_arenas)\n",
    "\n",
    "    # create folder 'season arenas' if it doesn't exist\n",
    "    folder_path = 'season arenas'\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    \n",
    "    # loop through tables (1 - 12)\n",
    "    # first season is 2023-24 season\n",
    "    year = 2024\n",
    "    for i in range(1, 11):\n",
    "        arenas = tables[i].copy()\n",
    "        \n",
    "        # keep only relevant columns\n",
    "        arenas = arenas[['Team', 'Arena']]\n",
    "\n",
    "        # add capacities\n",
    "        #for a in arenas['Arena']:\n",
    "        #    arenas['Capacity'] = all_arenas_df[a, 'Capacity']\n",
    "        arenas['Capacity'] = arenas['Arena'].map(all_arenas_df['Capacity'])\n",
    "\n",
    "        # save the dataframe as a csv file\n",
    "        season_str = f\"{year - 1}-{str(year)[2:]}\"\n",
    "        file_name = f\"{season_str} season arenas.csv\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        arenas.to_csv(file_path, index = False)\n",
    "        year -= 1\n",
    "\n",
    "        # 2022-23 season has same arenas as 2023-24 season\n",
    "        if year == 2023:\n",
    "            season_str = f\"{year - 1}-{str(year)[2:]}\"\n",
    "            file_name = f\"{season_str} season arenas.csv\"\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            arenas.to_csv(file_path, index = False)\n",
    "            year -= 1\n",
    "\n",
    "        # no arenas for 2020-21 season\n",
    "        if year == 2021:\n",
    "            year -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ed0490-7480-4f7f-b8d7-b6af85b82131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad practice i know to get data from wikipedia, but this is just easier lol\n",
    "# not using for the attendance statistics, rather for the arenas used per year\n",
    "url_arenas = 'https://en.wikipedia.org/wiki/List_of_National_Hockey_League_attendance_figures'\n",
    "\n",
    "get_arenas(url_arenas, all_arenas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f8549-7f0b-4b5b-b556-b21617c144e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
